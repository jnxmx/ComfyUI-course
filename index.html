<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComfyUI для работы с нейросетями: изображение, анимация, звук</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div id="bg"></div>
    <div id="mobile-timeline">
    <div id="carousel-track"></div>
    </div>
    <div class="content-wrapper">
    <header>
        <h1>ComfyUI для работы с нейросетями:<br>изображение, анимация, звук</h1>

    </header>
    <main>
        <section id="about">
            <h3>О курсе</h3>
            <p><a href="https://www.comfy.org/">ComfyUI</a> это <span class="highlight">самый мощный</span>, <span class="highlight">гибкий</span> и <span class="highlight">широко используемый</span> инструмент для визуальной генерации с помощью ИИ. В отличие от коммерческих веб-сервисов (Midjorney, Runway, Elevenlabs и подобных), ComfyUI позволяет работать без ограничений, запуская загруженные модели ИИ прямо на вашем компьютере или в облачных сервисах. Полный контроль над процессом генерации делает работу с нейросетями творческой и увлекательной, а результат адаптированным под задачу. Это передовой, активно развивающийся и поддерживаемый инструмент и, разобравшись с основами, вы сможете в нём работать с новыми ИИ моделями любого типа в дальнейшем.</p><p>Курс может быть интересен как тем, кто уже использует в работе ИИ-инструменты и хочет сделать следующий шаг, так и тем, кто только приступает к изучению возможностей ИИ и ищет структурированный подход. </p>
        </section>

        <section id="cloud">
            <h3>Работа в облаке</h3>
            <p>Вам <span class="highlight">не понадобится мощный компьютер</span> для работы на курсе. Вы научитесь запускать ComfyUI в облачных сервисах с низкой стоимостью почасовой аренды. Зачастую это более экономически оправданно, чем покупка профессиональной видеокарты.</p><p>Подготовленный для быстрого и удобного запуска аккаунт, который вы будете использовать на курсе, останется у вас после окончания, и вы сможете продолжать его использовать.</p>
        </section>

        <section id="structure">
            <h3>Формат и структура курса</h3>
            <ul>
                <li>Два месяца, <span class="highlight">18 групповых дистанционных занятий</span>, 2 раза в неделю в Zoom.</li>
                <li>Продолжительность каждого занятия 3 часа.</li>
                <li>Практические занятия совмещают изучение новых инструментов и их непосредственное использование.</li>
                <li>Вместо домашних заданий на курсе будут выделены четыре занятия посвящённые самостоятельной работе над творческими заданиями и итоговым проектом с комментированием результатов и разбором возникающих трудностей.</li>
                <li>Теоретическая часть даст общее понимание того, чем по сути являются генеративные модели ИИ, как они обучаются и как работают, а также как устроена инфраструктура вокруг них.</li>
                <li>Онлайн-поддержка: чат с преподавателем и однокурсниками для вопросов и обсуждений между занятиями.</li>
            </ul>
        </section>

        <section id="results">
            <h3>Результаты обучения</h3>
            <ul>
                <li>Вы научитесь работать с локальными моделями ИИ в ComfyUI и запускать как в облаке, так и на локальном компьютере.</li>
                <li>Вы освоите возможности лучшей на сегодняшний день ИИ модели для генерации изображений <span class="highlight">Flux Dev</span>, пришедшей на смену Stable Diffusion</li>
                <li>Вы ознакомитесь с передовыми локальными <span class="highlight">ИИ моделями для видеогенерации</span>, научитесь их использовать и оптимизировать.</li>
                <li>Вы научитесь дообучать модели и натренируете Flux на собственных данных.</li>
                <li>Вы научитесь таким применениям локальных ИИ моделей, как создание звуков, смешивание новых изображений из существующих, копирование позы, мимики и голоса.</li>
                <li>У вас останется набор разобранных на занятиях файлов, готовых к запуску самых разных генеративных задач.</li>
                <li>Созданные в рамках достаточно свободных творческих заданий изображения и видео могут стать началом вашего портфолио ИИ работ.</li>
            </ul>
        </section>

        <section id="audience">
            <h3>Кому это будет полезно</h3>
            <p>Курс адресован в первую очередь независимым авторам для обогащения их художественной практики, предполагающей свободу, понимание используемых инструментов и отсутствие ограничений.</li>
            <ul>
                <li>Художникам, чтобы найти свой авторский подход и и самостоятельно выполнять с помощью ИИ бóльшую сферу работы.</li>
                <li>Фильммейкерам, чтобы свободно экспериментировать с передовыми технологиями в генеративном видео.</li>
                <li>Дизайнерам, чтобы вывести работу с ИИ за рамки концептуализации, получая качественно новый уровень результата.</li>
                <li>Архитекторам для применения ИИ в быстром создании настраиваемых и анимированных визуализаций.</li>
                <li>Разработчикам и инженерам, чтобы использовать ComfyUI как бэкенд для интеграции в приложения, веб-сервисы и интерактивные инсталляции.</li>
                <li>Исследователям и энтузиастам курс покажет доступные на сегодняшний день возможности и вызовы генеративного ИИ, и поможет глубже погрузиться в технологию.</li>
                <li>Студиям и агенствам курс может помочь повысить эффективность бизнеса внедрив новые инструменты и сократив затраты на оборудование.</li>
            </ul>
        </section>

        <section id="requirements">
            <h3>Требования</h3>

            <p>Курс, при всей его фундаментальности и технической глубине, задумывался как доступный и дружелюбный. ComfyUI станет в процессе обучения таким же понятным и привычным для вас, как графический редактор или программах для монтажа. Навыки программирования не требуются и не понадобятся. Для учёбы на курсе нужны только:</p>
            <ul>
                <li>Шесть часов в неделю</li>
                <li>Высокоскоростной интернет</li>
                <li>Базовая компьютерная грамотность</li>
                <li>Интерес и терпение</li>
            </ul>
        </section>

        <section id="instructor">
            <h3>О преподавателе</h3>
            <p><span class="highlight">Иван Якушев</span> — цифровой визуальный художник и преподаватель.</p>
            <p>С 2022 года преподаёт во Франции в национальной высшей школе искусства и дизайна <a href="https://www.ensad-nancy.fr/" target="_blank">ENSAD Nancy</a>. С 2024 года ведёт практический курс по применению ИИ в искусстве для студентов-художников ENSAD Nancy и инженеров <a href="https://mines-nancy.univ-lorraine.fr/" target="_blank">École des Mines Nancy</a>.</p>
            <p>Организовывал и проводил воркшоп по нейросетевому искусству для студентов художественных вузов Бельгии, Италии и Германии в рамках программы Erasmus. С 2015 по 2022 год преподавал в <a href="https://design.hse.ru/" target="_blank">HSE Art and Design School</a> визуальную коммуникацию и алгоритмическую графику.</p>
            <p>Видеоработы принимали участие в таких фестивалях, как International Short Film Festival Oberhausen, MIEFF и др. </p>
            <p><a href="https://ensad-nancy.eu/2024/10/11/au-dela-de-la-fatigue/">Персональная выставка</a> художественных работ в Galerie S002 (Франция).</p>
            <p>Также участвовал в групповой выставке «<a href="https://kholmy.vzmoscow.ru/ai">ИИ: и? Нейронные сети и творческий процесс</a>» в галерее Краснохолмская, Москва и др.</p>
        </section>

 <section id="schedule">
            <h3>План курса</h3>
            <ol>
                <li>
                    Знакомство с ComfyUI и друг с другом
                    <ul>
                        <li>Воркфлоу, ноды, соединения, загрузка моделей. Примеры. ComfyUI Manager.</li>
                    </ul>
                </li>
                <li>
                    Развёртывание ComfyUI в облаке
                    <ul>
                        <li>Требования к железу и откуда они берутся: NVidia CUDA, видеопамять. Облачные сервисы и docker контейнеры. Репозиторий ИИ моделей Hugging Face и управление файлами. Настройка аккаунта и первый запуск.</li>
                    </ul>
                </li>
                <li>
                    Как работает генеративный ИИ
                    <ul>
                        <li>Ключевые концепции диффузионных моделей, Diffusion Models, CLIP, VAE, Steps, Latent space</li>
                    </ul>
                </li>
                <li>
                    Генерация изображений: промпты и основные параметры
                    <ul>
                        <li>Создание изображений с использованием базовой модели Flux.</li>
                    </ul>
                </li>
                <li>Самостоятельная работа: творческое задание 1<ul>
                        <li>Совместная рабочая сессия, комментарии и вопросы</li>
                    </ul>
                </li>
                <li>
                    LoRA: Адаптация базовых моделей
                    <ul>
                        <li>Установка и активация готовых LoRA в ComfyUI. Персонаж, визуальный стиль, концепт. Репозиторий civit.ai. Подготовка датасета к обучению.</li>
                    </ul>
                </li>
                <li>
                    LoRA: Тренировка модели на своих данных
                    <ul>
                        <li>Запуск в облаке обучения вашей собственной модели. Практическая отработка навыков с предыдущих занятий. Тест результата.</li>
                    </ul>
                </li>
                <li>
                    Управление объёмом и контурами
                    <ul>
                        <li>ControlNet: Canny & Depth. Генерация и применение карт глубины.</li>
                    </ul>
                </li>
                <li>Самостоятельная работа: творческое задание 2<ul>
                        <li>Совместная рабочая сессия, комментарии и вопросы</li>
                    </ul>
                </li>
                <li>
                    Редактирование частей изображений
                    <ul>
                        <li>Inpainting, автоматическое выделение объектов и фона.</li>
                    </ul>
                </li>
                <li>
                    Трансформация изображений с помощью компьютерного зрения
                    <ul>
                        <li>Визуальные адаптеры и VLM. Извлечение визуальных признаков из изображений для переработки.</li>
                    </ul>
                </li>
                <li>
                    Видео на основе текста и изображений
                    <ul>
                        <li>Обзор актуальных моделей для генерации видео и их использования в ComfyUI.</li>
                    </ul>
                </li>
                <li>
                    Видео: способы глубокого контроля
                    <ul>
                        <li>Интерполяция ключевых кадров. ControlNet и LoRA для движения.</li>
                    </ul>
                </li>
                <li>
                    Речь и звук
                    <ul>
                        <li>Синтез и распознавание речи, копирование голоса, звуковые генерации. LivePortrait, Wav2Lip: управление мимикой, связь анимации лица с озвучкой.</li>
                    </ul>
                </li>
                <li>Самостоятельная работа: творческое задание 3<ul>
                        <li>Совместная рабочая сессия, комментарии и вопросы</li>
                    </ul>
                </li>
                <li>
                    Абстрактная экспериментальная анимация
                    <ul>
                        <li>Бесконечные и зацикленные анимации с AnimateDiff.</li>
                    </ul>
                </li>
                <li>
                    Консультация по локальной установке ComfyUI и начало работы над итоговым проектом
                    <ul>
                        <li>Совместная рабочая сессия, комментарии и вопросы</li>
                    </ul>
                </li>
                <li>
                    Презентация итогового проекта
                    <ul>
                        <li>Обсуждение, комментарии и вопросы</li>
                    </ul>
                </li>
            </ol>
        </section>

        <section id="pricing">
            <h3>Стоимость</h3>
            <p><span class="highlight">48000 рублей или 450 евро</span><br>В стоимость курса включено более 60 часов работы в облаке<br>на видеокартах NVidia RTX 4090</p>
        </section>

        <section id="schedule-dates">
            <h3>Расписание первого потока</h3>
            <p>22 февраля — 26 апреля<br>Вторник 19:00 — 22:00<br>Суббота 13:00 — 16:00<br>[UTC+3]</p>
        </section>

        <iframe data-tally-src="https://tally.so/embed/nGXAPQ?alignLeft=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="736" frameborder="0" marginheight="0" marginwidth="0" title="Нейросети с ComfyUI в облаке"></iframe>
        <script>var d=document,w="https://tally.so/widgets/embed.js",v=function(){"undefined"!=typeof Tally?Tally.loadEmbeds():d.querySelectorAll("iframe[data-tally-src]:not([src])").forEach((function(e){e.src=e.dataset.tallySrc}))};if("undefined"!=typeof Tally)v();else if(d.querySelector('script[src="'+w+'"]')==null){var s=d.createElement("script");s.src=w,s.onload=v,s.onerror=v,d.body.appendChild(s);}</script>

    <footer>
        <p>© 2025 Иван Якушев</p>
    </footer>
        </div>
     <script>
    const DURATION_MS = 5000; 

    const topStart     = [12, 78, 185];  // #d97725 217, 119, 37
    const topEnd       = [216, 206, 201];   // #0c4eb9
    const bottomEnd  = [12, 78, 185];   // #0c4eb9
    const bottomStart    = [216, 206, 201];  // #d97725
    
    function lerp(a, b, t) {
      return a + (b - a) * t;
    }

    function interpolateColor(colorA, colorB, t) {
      return [
        Math.round(lerp(colorA[0], colorB[0], t)),
        Math.round(lerp(colorA[1], colorB[1], t)),
        Math.round(lerp(colorA[2], colorB[2], t))
      ];
    }

    function rgbToString(rgbArr) {
      return `rgb(${rgbArr[0]}, ${rgbArr[1]}, ${rgbArr[2]})`;
    }

    function pingPong(frac) {
      if (frac < 0.5) {
        return frac * 2;       // 0..1
      } else {
        return 1 - (frac - 0.5) * 2; // 1..0
      }
    }

    function animateGradient() {
      const now = Date.now();
      const tCycle = (now % DURATION_MS) / DURATION_MS;
      const t = pingPong(tCycle);

      const topColorArr    = interpolateColor(topStart, topEnd, t);
      const bottomColorArr = interpolateColor(bottomStart, bottomEnd, t);

      const topColor    = rgbToString(topColorArr);
      const bottomColor = rgbToString(bottomColorArr);

      const gradientStr = `linear-gradient(
        to bottom,
        ${topColor} 0%,
        #d8cec9 15%,
        #d8cec9 100%
      )`;

      document.getElementById('bg').style.background = gradientStr;

      requestAnimationFrame(animateGradient);
    }
    requestAnimationFrame(animateGradient);
  </script>
    <script src="carousel-mobile.js"></script>
</body>
</html>
