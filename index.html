<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComfyUI для работы с нейросетями: изображение, анимация, звук</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div id="bg"></div>
    <canvas id="video-carousel"></canvas>
    <div class="content-wrapper">
    <main>
        <section id="title">
            <h1>ComfyUI для работы с нейросетями:<br>изображение, анимация, звук</h1>
            <p>Онлайн | 18 групповых занятий</p> <!--| 58000₽/580€</p>-->
        </section>
        
        <section id="about">
            <h3>О курсе</h3>
            <p><a href="https://www.comfy.org/">ComfyUI</a> это <span class="highlight">самый передовой</span>, <span class="highlight">гибкий</span> и <span class="highlight">широко используемый</span> инструмент для визуальной генерации с помощью ИИ. Это универсальный интерфейс для запуска свободно распространяемых моделей генеративного ИИ (таких как WAN, Flux, Stable Diffusion, Qwen и многих других) в облаке или на вашем компьютере.</p> 
            <p>В отличие от коммерческих веб‑сервисов (Midjorney, Runway, Elevenlabs и подобных), ComfyUI позволяет работать без ограничений, подписок и модерации. Это активно развивающийся и поддерживаемый open‑source сообществом инструмент, и, разобравшись с основами, вы сможете в нём работать с новыми ИИ моделями любого типа в дальнейшем. Полный контроль над процессом генерации делает работу с нейросетями творческой и увлекательной, а результат адаптированным под задачу.</p>
            <p>Курс может быть интересен как тем, кто уже использует в работе ИИ‑инструменты и хочет сделать следующий шаг, так и тем, кто только приступает к изучению возможностей ИИ и ищет фундаментальный и структурированный подход.</p>
            <video src="assets/video_example.mp4" width="100%" muted autoplay loop playsinline aria-label="Preview of ComfyUI interface">
                 <img src="img/screenshot.png" width="100%" alt="Screenshot of ComfyUI interface">
            </video>
        </section>

        <section id="cloud">
            <h3>Работа в облаке</h3>
            <p>Вам <span class="highlight">не понадобится мощный компьютер</span> для работы на курсе. Вы научитесь запускать ComfyUI в облачных сервисах с низкой стоимостью почасовой аренды. Зачастую это более экономически оправданно, чем покупка профессиональной видеокарты.</p>
            <p>Подготовленный для быстрого и удобного запуска аккаунт, которым вы будете пользоваться на курсе, останется у вас после окончания, и вы сможете продолжать использовать его.</p>
        </section>

        <section id="structure">
            <h3>Формат и структура курса</h3>
            <ul>
                <li>Два месяца, <span class="highlight">18 групповых дистанционных занятий</span>, 2 раза в неделю в Zoom.</li>
                <li>Продолжительность каждого занятия 3 часа.</li>
                <li>Практические занятия совмещают изучение новых инструментов и их непосредственное использование.</li>
                <li>Теоретическая часть даст общее понимание того, чем по сути являются генеративные модели ИИ, как они обучаются и как работают, а также как устроена инфраструктура вокруг них.</li>
                <li>Онлайн‑поддержка: чат с преподавателем и однокурсниками для вопросов и обсуждений между занятиями.</li>
            </ul>
        </section>

        <section id="results">
            <h3>Результаты обучения</h3>
            <ul>
                <li>Вы научитесь работать с локальными моделями ИИ в ComfyUI и запускать как в облаке, так и на локальном компьютере.</li>
                <li>У вас останется аккаунт для работы в облаке и набор разобранных на занятиях файлов выполняющих самые разные генеративные задачи.</li>
                <li>Вы освоите возможности моделей для генерации и редактирования изображений <span class="highlight">Flux Dev/Kontext</span>, <span class="highlight">Qwen Image/Edit</span>, <span class="highlight">SDXL</span> и других.</li>
                <li>Вы ознакомитесь с принципами видеогенерации, научитесь использовать <span class="highlight">WAN 2.2</span> для генерации коротких анимаций.</li>
                <li>Вы научитесь дообучать модели и натренируете Flux на собственных данных.</li>
                <li>Вы научитесь таким применениям локальных ИИ моделей, как создание звуков, смешивание новых изображений из существующих, копирование позы, мимики и голоса.</li>
            </ul>
        </section>

        <section id="audience">
            <h3>Кому это будет полезно</h3>
            <p>Курс адресован в первую очередь независимым авторам для обогащения их художественной практики, предполагающей свободу, понимание используемых инструментов и отсутствие ограничений.</p>
            <ul>
                <li>Художникам, чтобы найти свой авторский подход и самостоятельно выполнять с помощью ИИ бóльшую сферу работы.</li>
                <li>Фильммейкерам, чтобы свободно экспериментировать с передовыми технологиями в генеративном видео.</li>
                <li>Дизайнерам, чтобы вывести работу с ИИ за рамки концептуализации, получая качественно новый уровень результата.</li>
                <li>Архитекторам для применения ИИ в быстром создании визуализаций.</li>
                <li>Разработчикам и инженерам, чтобы использовать ComfyUI как бэкенд для интеграции в приложения, веб‑сервисы и интерактивные инсталляции.</li>
                <li>Исследователям и энтузиастам курс покажет доступные на сегодняшний день возможности и вызовы генеративного ИИ, и поможет глубже погрузиться в технологию.</li>
                <li>Студиям и агенствам курс может помочь повысить эффективность бизнеса внедрив новые инструменты.</li>
            </ul>
        </section>

        <section id="requirements">
            <h3>Требования</h3>

            <p>Курс, при всей его фундаментальности и технической глубине, задумывался как доступный и дружелюбный. ComfyUI станет в процессе обучения таким же понятным и привычным для вас, как графический редактор или программах для монтажа. Навыки программирования не требуются и не понадобятся. Для учёбы на курсе нужны только:</p>
            <ul>
                <li>Шесть часов в неделю</li>
                <li>Высокоскоростной интернет</li>
                <li>Базовая компьютерная грамотность</li>
                <li>Базовый английский язык</li>
                <li>Интерес и терпение</li>
            </ul>
        </section>

        <section id="instructor">
            <h3>О преподавателе</h3>
            <p><span class="highlight">Иван Якушев</span> — цифровой визуальный художник и преподаватель.</p>
            <p>С 2022 года преподаёт во Франции в национальной высшей школе искусства и дизайна <a href="https://www.ensad-nancy.fr/" target="_blank">ENSAD Nancy</a>. С 2024 года ведёт практический курс по применению ИИ в искусстве для студентов‑художников ENSAD Nancy и инженеров <a href="https://mines-nancy.univ-lorraine.fr/" target="_blank">École des Mines Nancy</a>.</p>
            <p>Организовывал и проводил воркшопы по нейросетевому искусству для студентов художественных вузов Франции, Бельгии, Италии и Германии в рамках программы Erasmus. С 2015 по 2022 год преподавал в <a href="https://design.hse.ru/" target="_blank">HSE Art and Design School</a> визуальную коммуникацию и алгоритмическую графику.</p>
            <p>Видеоработы принимали участие в таких фестивалях, как International Short Film Festival Oberhausen, MIEFF и др.</p>
            <p>Персональная выставка художественных работ в Galerie S001 (Франция) в соавторстве с Александрой Карелиной. Видеоперформанс с риалтайм генерацией "Noms des eaux" для инициатив K1NO1 (Франция) и ACT (Германия). Участие в групповой выставке «ИИ: и? Нейронные сети и творческий процесс» в галерее Краснохолмская, Москва и др.</p>
        </section>

        <section id="schedule">
            <h3>Программа курса</h3>
            <ol>
                <li>
                    <sup>05.10</sup> Знакомство с ComfyUI и друг с другом
                    <ul>
                        <li>Локальные модели ИИ, в чём отличие от сервисов, и как с ними работать. Интерфейс ComfyUI: воркфлоу, ноды, соединения.</li>
                    </ul>
                </li>
                <li>
                    <sup>08.10</sup> Запуск нейросетей в облаке
                    <ul>
                        <li>Откуда берутся технические требования: GPU, NVidia CUDA, видеопамять. Настройка аккаунта и первый запуск. Docker контейнеры. Репозиторий ИИ моделей Hugging Face.</li>
                    </ul>
                </li>
                <li>
                    <sup>12.10</sup> Как работает генеративный ИИ
                    <ul>
                        <li>Ключевые концепции диффузионных моделей, DiT/UNET, CLIP/Text Encoder, VAE, Latent space, Noise, Steps.</li>
                    </ul>
                </li>
                <li>
                    <sup>15.10</sup> Приступаем к генерации изображений
                    <ul>
                        <li>Текстовые промпты и основные параметры. Создание изображений с использованием Flux Dev/Krea, Qwen Image, Stable Diffusion.</li>
                    </ul>
                </li>
                <li>
                    <sup>19.10</sup> Работа с размером изображений и denoise
                    <ul>
                        <li>«Слепое» увеличение с помощью upscale моделей и «creative upscale» с помощью диффузии. Denoise на примере SDXL и Flux.</li>
                    </ul>
                </li>
                <li>
                    <sup>22.10</sup> LoRA: Адаптация базовых моделей
                    <ul>
                        <li>Установка и активация готовых LoRA в ComfyUI. Персонаж, визуальный стиль, концепт. Репозиторий civit.ai. Подготовка датасета к обучению.</li>
                    </ul>
                </li>
                <li>
                    <sup>26.10</sup> LoRA: Тренировка модели на своих данных
                    <ul>
                        <li>Запуск в облаке обучения модели на ваших данных. Тест результата.</li>
                    </ul>
                </li>
                <li>
                    <sup>29.10</sup> Управление объёмом, контурами и позами
                    <ul>
                        <li>ControlNet. Depth, OpenPose, Canny. Генерация и применение карт глубины.</li>
                    </ul>
                </li>
                <li>
                    <sup>02.11</sup> Редактирование частей изображения
                    <ul>
                        <li>Inpainting модели, маски, сегментация, автоматическое выделение объектов и фона.</li>
                    </ul>
                </li>
                <li>
                    <sup>05.11</sup> Визуальные адаптеры
                    <ul>
                        <li>Извлечение визуальных признаков из изображений для переработки. IP-Adapter для SDXL, ACE/USO, Redux для Flux.</li>
                    </ul>
                </li>
                <li>
                    <sup>09.11</sup> Модели для редактирования изображений
                    <ul>
                        <li>Qwen Edit и Flux Kontext. Изменение ракурса, сохранение персонажа, совмещение изображений. Использование LoRA для конкретных задач.</li>
                    </ul>
                </li>
                <li>
                    <sup>12.11</sup> Видео на основе текста и изображений
                    <ul>
                        <li>Актуальные модели для генерации видео (WAN 2.2) и их использование в ComfyUI.</li>
                    </ul>
                </li>
                <li>
                    <sup>16.11</sup> Видео: способы глубокого контроля
                    <ul>
                        <li>VACE. Интерполяция ключевых кадров. ControlNet в видео.</li>
                    </ul>
                </li>
                <li>
                    <sup>19.11</sup> LoRA для видео
                    <ul>
                        <li>Установка и активация готовых LoRA в ComfyUI.</li>
                    </ul>
                </li>
                <li>
                    <sup>23.11</sup> Речь, звук, копирование мимики
                    <ul>
                        <li>Генерация аудио. Синтез и распознание речи, звуковые генерации. Генерация видео с речью.</li>
                    </ul>
                </li>
                <li>
                    <sup>26.11</sup> Длинные и зацикленные анимации
                    <ul>
                        <li>Context Window. V2V с низким denoise. S2V видео с говорящими персонажами.</li>
                    </ul>
                </li>
                <li>
                    <sup>30.11</sup> ComfyUI на своём компьютере
                    <ul>
                        <li>Установка и оптимизация для компьютеров с видеокартами NVidia. Бэкап в облаке. Консультация и не вошедший в остальные занятия материал.</li>
                    </ul>
                </li>
                <li>
                    <sup>07.12</sup> Неделя самостоятельной работы и презентация итогового проекта
                    <ul>
                        <li>Просмотр и обсуждение финальных проектов.</li>
                    </ul>
                </li>
            </ol>
        </section>
        <section id="faq">
            <h3>Часто задаваемые вопросы</h3>

            <p>— Обязательно ли работать в облаке? Я хочу использовать свой компьютер.</p>
            <p>Да, облако — важная часть курса. Модели ИИ могут быть чрезвычайно требовательны к железу, а предустановка может сбивать с толку. В облаке на мощных видеокартах модели будут работать на высокой скорости, и будут работать одинаково и стабильно. Ключевое, освоив запуск в облаке, вы сможете запускать онлайн генерации с любого устройства откуда угодно.</p>
            <p>Ближе к концу курса будет отдельное занятие про установку и запуск на локальном компьютере, и мы подробно обсудим целесообразность и возможности в конкретных случаях.</p>

            <p>— Будут ли записи занятий?</p>
            <p>Курс строится как живая работа в группе: семинары, обсуждени и совместная практика. Я не записываю занятия, но ключевые материалы и ссылки будут появляться в Telegram‑группе — вы ничего не потеряете. Для пропущенных занятий или для персонального архива вы сможете записать занятие самостоятельно в Zoom.</p>

            <p>— Можно ли оплатить курс частями?</p>
            <p>Участие в курсе возможно только после полной оплаты.</p>
        </section>

        <section id="pricing">
            <section id="schedule-dates">
            <h3>Расписание третьего потока</h3>
            <p>5 октября — 7 декабря<br>Среда 19:00 — 22:00<br>Воскресенье 13:00 — 16:00<br>[Время по UTC+3]</p>
        </section>
        
            <!--<iframe data-tally-src="https://tally.so/embed/mK9dL7?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="708" frameborder="0" marginheight="0" marginwidth="0" title="Третий поток"></iframe>
            <script>var d=document,w="https://tally.so/widgets/embed.js",v=function(){"undefined"!=typeof Tally?Tally.loadEmbeds():d.querySelectorAll("iframe[data-tally-src]:not([src])").forEach((function(e){e.src=e.dataset.tallySrc}))};if("undefined"!=typeof Tally)v();else if(d.querySelector('script[src="'+w+'"]')==null){var s=d.createElement("script");s.src=w,s.onload=v,s.onerror=v,d.body.appendChild(s);}</script>
            --><h3>Набор закрыт</h3>
            <p>Группа на третий поток сформирована, следующий курс в 2026 году</p>
        </section>

    <footer>
        <p>© 2025 Иван Якушев <a href="docs/public_offer.pdf">Договор-офферта</a><script>
  // разбиваем на части
  const nameParts  = ['Яку','шев',' Иван',' Евг','еньевич'];
  const innParts   = ['7736','0543','8286'];
  const phoneParts = ['+7','916','244','5476'];
  const mailParts  = ['ivan','.yakushev','@gmail','.com'];

  const fullName = nameParts.join('');
  const inn      = innParts.join('');
  const phone    = phoneParts.join(' ');
  const email    = mailParts.join('');

  // теперь можно выводить в DOM или рисовать на canvas
  document.addEventListener('DOMContentLoaded', () => {
    const box = document.getElementById('contacts');
    box.textContent = fullName + '\n' + inn + '\n' + phone + ' ' + email;
  });
</script>

<div id="contacts"></div></p>
    </footer>
    </div>
    <script src="carousel.js"></script>
    <script src="gradient.js"></script>

</body>
</html>
